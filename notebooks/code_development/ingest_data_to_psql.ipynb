{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the data to psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nyc_taxi.etl.psql_tools import TransactionManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the headers of all files and unify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_header(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return f.readline().replace('\\n', '').strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = list(Path('../data/green_taxi').glob('*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = pd.DataFrame(dict(path=filepaths, columns=[read_header(p) for p in filepaths]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-shared columns:\n",
      "{'pickup_longitude', 'improvement_surcharge', 'dropoff_longitude', 'dolocationid', 'congestion_surcharge', 'pulocationid', 'pickup_latitude', 'dropoff_latitude'}\n"
     ]
    }
   ],
   "source": [
    "header_union = reduce(\n",
    "    lambda x, y: x.union(y), \n",
    "    [set(c.split(',')) for c in headers['columns'].unique()])\n",
    "\n",
    "header_intersection = reduce(\n",
    "    lambda x, y: x.intersection(y), \n",
    "    [set(c.split(',')) for c in headers['columns'].unique()])\n",
    "\n",
    "print(f'Non-shared columns:\\n{header_union.difference(header_intersection)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_shared_column_dtypes = {\n",
    "    'congestion_surcharge': np.float,\n",
    "    'dolocationid': pd.Int64Dtype(),\n",
    "    'dropoff_latitude': np.float,\n",
    "    'dropoff_longitude': np.float,\n",
    "    'improvement_surcharge': np.float,\n",
    "    'pickup_latitude': np.float,\n",
    "    'pickup_longitude': np.float,\n",
    "    'pulocationid': pd.Int64Dtype()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files with same columns and import to psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(TransactionManager().conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_csv(path, extra_column_dtypes=non_shared_column_dtypes, all_columns=header_union):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={col: col.lower().strip() for col in df.columns})\n",
    "    \n",
    "    missing_columns = all_columns.difference(df.columns)\n",
    "    return df.assign(**{\n",
    "        col: pd.Series(len(df)*[np.nan], dtype=extra_column_dtypes[col]) \n",
    "        for col in missing_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataframe_to_psql(df, engine, table_name='nyc_green_taxi_records'):\n",
    "    df.to_sql(table_name, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_lines(path):\n",
    "    with open(path, 'r') as f:\n",
    "        f.readline()\n",
    "        return f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove window newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '\\n'.strip():\n",
    "    print('True...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mariosk/Desktop/green_tripdata_2018-06.csv', 'r') as f:\n",
    "    updated_text = f.read().replace(r'\\r', '')\n",
    "    updated_text = '\\n'.join(list(filter(\n",
    "        lambda x: x.strip(), \n",
    "        updated_text.split('\\n'))))\n",
    "    \n",
    "with open('/home/mariosk/Desktop/green_tripdata_2018-06.csv', 'w') as f:\n",
    "    f.write(updated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double-check for empty lines in the beginning of csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in filepaths:\n",
    "    second_line = read_first_lines(path)\n",
    "    if second_line.strip() == '':\n",
    "        print(path, ': ', second_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files with more elements in rows as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prob = pd.read_csv('../../data/green_taxi/green_tripdata_2014-04.csv', header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_ignoring_empty_extra_columns(path):\n",
    "    with open(path, 'r') as f:\n",
    "        header = f.readline().strip().split(',')\n",
    "        first_line = f.readline().strip().split(',')\n",
    "\n",
    "    extra_columns = len(first_line) - len(header)\n",
    "    if extra_columns == 0:\n",
    "        df = pd.read_csv(path)\n",
    "    else:\n",
    "        extended_header = header + list(range(extra_columns))\n",
    "        df = pd.read_csv(path, names=extended_header, skiprows=1, header=None)\n",
    "        df = df[header]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>Lpep_dropoff_datetime</th>\n",
       "      <th>Store_and_fwd_flag</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>Pickup_longitude</th>\n",
       "      <th>Pickup_latitude</th>\n",
       "      <th>Dropoff_longitude</th>\n",
       "      <th>Dropoff_latitude</th>\n",
       "      <th>Passenger_count</th>\n",
       "      <th>Trip_distance</th>\n",
       "      <th>Fare_amount</th>\n",
       "      <th>Extra</th>\n",
       "      <th>MTA_tax</th>\n",
       "      <th>Tip_amount</th>\n",
       "      <th>Tolls_amount</th>\n",
       "      <th>Ehail_fee</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Payment_type</th>\n",
       "      <th>Trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-01 00:00:00</td>\n",
       "      <td>2014-04-01 14:24:20</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.45</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-01 00:00:00</td>\n",
       "      <td>2014-04-01 17:21:33</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.987663</td>\n",
       "      <td>40.780872</td>\n",
       "      <td>1</td>\n",
       "      <td>8.95</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-01 00:00:00</td>\n",
       "      <td>2014-04-01 15:06:18</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.946922</td>\n",
       "      <td>40.831764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.32</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-01 00:00:00</td>\n",
       "      <td>2014-04-01 08:09:27</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.947670</td>\n",
       "      <td>40.808651</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-01 00:00:00</td>\n",
       "      <td>2014-04-01 16:15:13</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.09</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime Lpep_dropoff_datetime Store_and_fwd_flag  \\\n",
       "0         2  2014-04-01 00:00:00   2014-04-01 14:24:20                  N   \n",
       "1         2  2014-04-01 00:00:00   2014-04-01 17:21:33                  N   \n",
       "2         2  2014-04-01 00:00:00   2014-04-01 15:06:18                  N   \n",
       "3         2  2014-04-01 00:00:00   2014-04-01 08:09:27                  N   \n",
       "4         2  2014-04-01 00:00:00   2014-04-01 16:15:13                  N   \n",
       "\n",
       "   RateCodeID  Pickup_longitude  Pickup_latitude  Dropoff_longitude  \\\n",
       "0           1               0.0              0.0           0.000000   \n",
       "1           1               0.0              0.0         -73.987663   \n",
       "2           1               0.0              0.0         -73.946922   \n",
       "3           1               0.0              0.0         -73.947670   \n",
       "4           1               0.0              0.0           0.000000   \n",
       "\n",
       "   Dropoff_latitude  Passenger_count  Trip_distance  Fare_amount  Extra  \\\n",
       "0          0.000000                1           7.45         23.0    0.0   \n",
       "1         40.780872                1           8.95         31.0    1.0   \n",
       "2         40.831764                1           1.32          6.5    0.0   \n",
       "3         40.808651                5           0.10          3.0    0.0   \n",
       "4          0.000000                1           7.09         23.5    0.0   \n",
       "\n",
       "   MTA_tax  Tip_amount  Tolls_amount  Ehail_fee  Total_amount  Payment_type  \\\n",
       "0      0.5         0.0           0.0        NaN          23.5             2   \n",
       "1      0.5         0.0           0.0        NaN          32.5             2   \n",
       "2      0.5         0.0           0.0        NaN           7.0             2   \n",
       "3      0.5         0.0           0.0        NaN           3.5             2   \n",
       "4      0.5         4.7           0.0        NaN          28.7             1   \n",
       "\n",
       "   Trip_type  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv_ignoring_empty_extra_columns('../../data/green_taxi/green_tripdata_2014-04.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
